# Open Graph Medium to Large Scale Problem Statement
## Problem Statement
Graph data provides a powerful way to represent and identify linkages. How can the representation (graph data model) with graph machine learning assist in taking data science applications to enhanced levels is a critical capability. The problem statement explores how graph representation coupled with graph query (insights) coupled with graph machine learning (like GNNs. Etc.) can provide next generation viable business capability. The solution and approach also need to address optimal/viable architectures to work on optimal memory and overall commodity-based hardware (servers). This problem will explore an end to end nature on building scalable graph-based capability with a technical frame using big data, data pre and post processing, data models for Graph/ML/analytics consumption.
The requirement is to explore these aspects, we use the [SNAP product co-purchasing networks](https://snap.stanford.edu/data/#amazon). 
- The key task is to (first) identify a good problem to solve that will address some potential business use case (you need to identify this). 
- This solution (second) needs to include a graph-based approach with the steps identified in the submission/evaluation section. 
- The final (third)solution must showcase an integration to a mobile app/ web front end (with API integration). 
The data is based on the [open data based on a large ecommerce platform](https://snap.stanford.edu/data/#amazon)

## Technical Stack (Mandatory to follow):
| | |
| --- | --- |
| [Dataset Details Product co-purchasing networks SNAP](https://snap.stanford.edu/data/#amazon) | [Code IDE & Notebook](https://colab.research.google.com/)|
| [Dataset: Meta Data)[https://snap.stanford.edu/data/amazon-meta.html]|Languages & framework - Core: Python / Processing: Pyspark, Spark  3.4.0+2.4+ |
|  | [Graph DB Opion 1](https://janusgraph.org/)[Graph DB Opion 2](https://blazegraph.com/) |
| [Visualisation Tools](https://gephi.org/users/download/) : Other open source can be suggested.|[Graph Query Gremlin Interface](https://pypi.org/project/gremlinpython/) [RDF Graph Query Sparkl](https://rdflib.readthedocs.io/en/stable/intro_to_sparql.html)|


## Outcomes Expected
- Post understanding the dataset (both transaction and meta data) identify a problem that you would want to solve. Clearly articulate the problem statement.
- Data processing (including Loading and transformations) of the data set (combination of pyspark & python-based code) or other high-performance libraries (in case being used, need to mention with details)
- The data processing/analysis needs to use both transaction and meta-data(semi/(un)structured)
- Creation of intermediate and base analytical data models (using both transaction and meta data)
- Create the graph-based model to help solve your problem statement basis the standard libraries mentioned; in case you have a better library, please call-out purpose of using them including providing specifics on them.
- In case the models require post process for computation; please factor the needful details on how they have been used.
- The final (third)solution must showcase an integration to a mobile app/ web front end (with API integration).

## Submission & Evaluation Broad Metrics (using Technical Stack)
- Problem statement definition (well-defined)
- Pre-processing and data cleaning (including standardising)
- Building reference/base data sets that facilitate modelling
- Exploratory Data Analysis (linked to problem statement)
- Data Processing pipelines
- Model Build Approach & Selection (includes testing) (using Graph based approach)
- Model Execution |Results & relevance as per problem statement
- Integration Approach | Mobile Application or Web Application
- Model Management and Performance Tracking Approach
- Guidance to Code level 
a.	Inline | Code | Documentation | Markdowns
b.	High Quality (modular, coding guidelines, etc.)
c.	Optimisations and efficiency codified basis your assignment 
i.	Algorithm/Time complexity, scalability & efficiency) 
ii.	Performance (time, memory metrics, etc.)
iii.	integrations
- Submission Specifics  
- Must be a notebook / project code (runnable live) as per platforms indicated above.
- Notebook must be named: <OG_project_NameOfTeam_Person>.ipynb
- Additional Document (if required): <OG_project_NameOfTeam_Person>.doc
- Additional aspects can also be covered in the notebook as markdown or additional document can also be considered.
- Code must be high quality and shared for evaluation
